{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the shortest distance matrix:  ../preparing_data/surat_shortest_distance_matrix.npy\n",
      "Max length:  50954.239672192\n",
      "Min length:  0.0\n",
      "Number of nodes:  2508\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# pytorch lightning\n",
    "import lightning as pl\n",
    "file_name = \"../preparing_data/surat_shortest_distance_matrix.npy\"\n",
    "\n",
    "# read the shortest distance matrix\n",
    "print(\"Reading the shortest distance matrix: \", file_name)\n",
    "sdm = np.load(file_name)\n",
    "\n",
    "# normalize the distance matrix\n",
    "maxLengthy = np.max(sdm)\n",
    "sdm = sdm/maxLengthy\n",
    "print(\"Max length: \", maxLengthy)\n",
    "print(\"Min length: \", np.min(sdm))\n",
    "\n",
    "# get the number of nodes\n",
    "n= sdm.shape[0]\n",
    "print(\"Number of nodes: \", n)\n",
    "\n",
    "def get_node(index):\n",
    "    node1_index = index // (n-1)  ## row index\n",
    "    node2_index = index % (n-1)  ## column index\n",
    "    return node1_index, node2_index\n",
    "\n",
    "\n",
    "def get_batch(index_list):\n",
    "    l = len(index_list)\n",
    "    x1_batch = np.zeros((l, n))\n",
    "    x2_batch = np.zeros((l, n))\n",
    "    y_batch = np.zeros((l, 1))\n",
    "    z = 0\n",
    "    for i in index_list:\n",
    "        node1, node2 = get_node(i)\n",
    "        if node2 >= node1:\n",
    "            node2 += 1\n",
    "        print(type(node1), type(node2), type(z))\n",
    "        x1_batch[z][node1] = 1\n",
    "        x2_batch[z][node2] = 1\n",
    "        y_batch[z] = sdm[node1][node2]\n",
    "        z += 1\n",
    "    return x1_batch, x2_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_node(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n",
      "<class 'int'> <class 'int'> <class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0.02260066],\n",
       "        [0.04162863],\n",
       "        [0.03606479],\n",
       "        [0.11176997],\n",
       "        [0.09337557],\n",
       "        [0.07152452],\n",
       "        [0.14513639],\n",
       "        [0.09688669],\n",
       "        [0.09988087],\n",
       "        [0.07802231]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available.\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available.\")\n",
    "else:\n",
    "    print(\"MPS is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dry run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the shortest distance matrix:  ../preparing_data/surat_shortest_distance_matrix.npy\n",
      "Max length:  50954.239672192\n",
      "Min length:  0.0\n",
      "Number of nodes:  2508\n",
      "Device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.0: 100%|█████████▉| 2507/2508 [03:05<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path:  ./model.pth\n",
      "Epoch: 0001 cost= 0.000619888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.0: 100%|█████████▉| 2507/2508 [02:59<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path:  ./model.pth\n",
      "Epoch: 0002 cost= 0.000058712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.0: 100%|█████████▉| 2507/2508 [03:07<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path:  ./model.pth\n",
      "Epoch: 0003 cost= 0.000042520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.0: 100%|█████████▉| 2507/2508 [03:08<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path:  ./model.pth\n",
      "Epoch: 0004 cost= 0.000034051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.0: 100%|█████████▉| 2507/2508 [03:06<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path:  ./model.pth\n",
      "Epoch: 0005 cost= 0.000028458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.0: 100%|█████████▉| 2507/2508 [03:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path:  ./model.pth\n",
      "Epoch: 0006 cost= 0.000024631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.0: 100%|█████████▉| 2507/2508 [03:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path:  ./model.pth\n",
      "Epoch: 0007 cost= 0.000022155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.0:  76%|███████▌  | 1903/2508 [02:20<00:44, 13.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 180\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m batch_x1, batch_x2, batch_y \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# print(type(batch_x1), type(batch_x2), type(batch_y))\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# print(batch_x1.shape, batch_x2.shape, batch_y.shape)\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# (2508, 2508) (2508, 2508) (2508, 1)\u001b[39;00m\n\u001b[1;32m    185\u001b[0m batch_x1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_x1, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[31], line 57\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(index_list)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_batch\u001b[39m(index_list):\n\u001b[1;32m     56\u001b[0m     l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index_list)\n\u001b[0;32m---> 57\u001b[0m     x1_batch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     x2_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((l, n))\n\u001b[1;32m     59\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((l, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# read the shortest distance matrix\n",
    "file_name = \"../preparing_data/surat_shortest_distance_matrix.npy\"\n",
    "print(\"Reading the shortest distance matrix: \", file_name)\n",
    "# shortest distance matrix (sdm)\n",
    "sdm = np.load(file_name)\n",
    "\n",
    "# normalize the distance matrix\n",
    "maxLengthy = np.max(sdm)\n",
    "sdm = sdm/maxLengthy\n",
    "print(\"Max length: \", maxLengthy)\n",
    "print(\"Min length: \", np.min(sdm))\n",
    "\n",
    "# get the number of nodes\n",
    "n= sdm.shape[0]\n",
    "print(\"Number of nodes: \", n)\n",
    "\n",
    "\n",
    "def get_node(index):\n",
    "    node1_index = index // (n-1)  ## row index\n",
    "    node2_index = index % (n-1)  ## column index\n",
    "    return node1_index, node2_index\n",
    "\n",
    "def get_batch(index_list):\n",
    "    l = len(index_list)\n",
    "    x1_batch = np.zeros((l, n))\n",
    "    x2_batch = np.zeros((l, n))\n",
    "    y_batch = np.zeros((l, 1))\n",
    "    z = 0\n",
    "    for i in index_list:\n",
    "        node1, node2 = get_node(i)\n",
    "        if node2 >= node1:\n",
    "            node2 += 1\n",
    "        x1_batch[z][node1] = 1\n",
    "        x2_batch[z][node2] = 1\n",
    "        y_batch[z] = sdm[node1][node2]\n",
    "        z += 1\n",
    "    return x1_batch, x2_batch, y_batch\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = n\n",
    "display_step = 1\n",
    "input_l = (n - 1)*n  # total number of input data samples (removing the diagonal elements)\n",
    "\n",
    "# Network Parameters\n",
    "n_input = n\n",
    "n_hidden_1 = int(n*0.2)\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 20\n",
    "n_output = 1\n",
    "\n",
    "# # tf Graph input\n",
    "# # node1 one-hot layer\n",
    "# x1 = tf.placeholder(\"float32\", [None, n_input], name=\"x1\")\n",
    "# # node2 one-hot layer\n",
    "# x2 = tf.placeholder(\"float32\", [None, n_input], name=\"x2\")\n",
    "# # output layer\n",
    "# y = tf.placeholder(\"float32\", [None, n_output], name=\"y\")\n",
    "\n",
    "# def multilayer_perceptron(x1, x2, weights, biases):\n",
    "#     # shared layer\n",
    "#     layer_11 = tf.add(tf.matmul(x1, weights['h1']), biases['b1'])\n",
    "#     layer_12 = tf.add(tf.matmul(x2, weights['h1']), biases['b1'])\n",
    "#     layer_1 = tf.concat([layer_11, layer_12], 1)\n",
    "#     # layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "#     # layer_2 = tf.nn.relu(layer_2)\n",
    "#     layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "#     layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, weights['h3']), biases['b3']))\n",
    "#     out_layer = tf.sigmoid(tf.add(tf.matmul(layer_3, weights['out']), biases['out']))\n",
    "#     return out_layer\n",
    "\n",
    "# # Store layers weight & bias\n",
    "# weights = {\n",
    "#     'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],  mean=0.0, stddev=0.01, dtype=tf.float32), name='h1'),\n",
    "#     'h2': tf.Variable(tf.truncated_normal([n_hidden_1*2, n_hidden_2], mean=0.0, stddev=0.01, dtype=tf.float32), name='h2'),\n",
    "#     'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3], mean=0.0, stddev=0.01, dtype=tf.float32), name='h3'),\n",
    "#     'out': tf.Variable(tf.truncated_normal([n_hidden_3, n_output], mean=0.0, stddev=0.01, dtype=tf.float32), name='wout')\n",
    "# }\n",
    "# biases = {\n",
    "#     'b1': tf.Variable(tf.truncated_normal([n_hidden_1], mean=0.0, stddev=0.01, dtype=tf.float32), name='b1'),\n",
    "#     'b2': tf.Variable(tf.truncated_normal([n_hidden_2], mean=0.0, stddev=0.01, dtype=tf.float32), name='b2'),\n",
    "#     'b3': tf.Variable(tf.truncated_normal([n_hidden_3], mean=0.0, stddev=0.01, dtype=tf.float32), name='b3'),\n",
    "#     'out': tf.Variable(tf.truncated_normal([n_output], mean=0.0, stddev=0.01, dtype=tf.float32), name='bout')\n",
    "# }\n",
    "\n",
    "# Construct model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n, n_hidden_1, n_hidden_2, n_hidden_3, n_output):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(n, n_hidden_1)\n",
    "        self.fc2 = nn.Linear(n_hidden_1*2, n_hidden_2)\n",
    "        self.fc3 = nn.Linear(n_hidden_2, n_hidden_3)\n",
    "        self.fc4 = nn.Linear(n_hidden_3, n_output)\n",
    "\n",
    "        # Initialize weights and biases with truncated normal distribution\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.trunc_normal_(m.bias, mean=0.0, std=0.01)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.fc1(x1)\n",
    "        x2 = self.fc1(x2)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "# select the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"Device: \", device)\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = MLP(n, n_hidden_1, n_hidden_2, n_hidden_3, n_output).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# cost = tf.losses.mean_squared_error(y, pred)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# tf.add_to_collection(\"optimizer\", optimizer)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# # Initializing the variables\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(input_l/batch_size) + 1\n",
    "    # Loop over all batches\n",
    "    random_index = np.random.permutation(input_l)\n",
    "    for j in tqdm(range(total_batch), desc=f\"Epoch: {epoch+1}\"):\n",
    "        start = j * batch_size\n",
    "        end = (j+1) * batch_size\n",
    "        if end >= input_l:\n",
    "            end = input_l\n",
    "        if start >= end:\n",
    "            break\n",
    "\n",
    "        # prepare the batch data\n",
    "        batch_x1, batch_x2, batch_y = get_batch(random_index[start:end])\n",
    "        batch_x1 = torch.tensor(batch_x1, dtype=torch.float32).to(device)\n",
    "        batch_x2 = torch.tensor(batch_x2, dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x1, batch_x2)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_cost += loss.item() / total_batch\n",
    "    # Display logs per epoch step\n",
    "    save_path = f\"./model.pth\"\n",
    "    print(\"Model saved in path: \", save_path)\n",
    "    # save the model\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "Loading the model from the saved file:  ./model.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model from the saved file\n",
    "print(\"device: \", device)\n",
    "print(\"Loading the model from the saved file: \", save_path)\n",
    "model.load_state_dict(torch.load(save_path, weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/629 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 629/629 [01:49<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error: 10119.797403883565\n",
      "max square error: 24750738.319608063\n",
      "min square error: 0.0\n",
      "mean absolute error: 72.79610066853664\n",
      "max absolute error: 4975.011388892297\n",
      "min absolute error: 0.0\n",
      "mean relative error: 0.017901513460987197\n",
      "max relative error: 191.2367618938278\n",
      "min relative error: 0.0\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "\n",
    "def get_eval_batch(p1, p2):\n",
    "    x1_batch = np.zeros(((p2-p1),n))\n",
    "    x2_batch = np.zeros(((p2-p1),n))\n",
    "    y_batch = np.zeros(((p2-p1),))\n",
    "    z = 0\n",
    "    for j in range(p1, p2):\n",
    "        node1, node2 = get_node(j)\n",
    "        if node2 >= node1:\n",
    "            node2 += 1\n",
    "        x1_batch[z][node1] = 1\n",
    "        x2_batch[z][node2] = 1\n",
    "        y_batch[z] = sdm[node1][node2]\n",
    "        z += 1\n",
    "    return x1_batch, x2_batch, y_batch\n",
    "\n",
    "\n",
    "batch_size = 10000\n",
    "total_batch = int(input_l/batch_size) + 1\n",
    "result = []\n",
    "real_dis = []\n",
    "for i in tqdm(range(total_batch)):\n",
    "    start = i * batch_size\n",
    "    end = (i+1)*batch_size\n",
    "    # print(start, end)\n",
    "    if end >= input_l:\n",
    "        end = input_l\n",
    "    \n",
    "    # print(start, end)\n",
    "    # result_temp = sess.run(pred, feed_dict={x1: batch_x1, x2:batch_x2})\n",
    "    # result = np.append(result, result_temp)\n",
    "    # real_dis = np.append(real_dis, batch_y)\n",
    "    \n",
    "    batch_x1, batch_x2, batch_y = get_eval_batch(start, end)\n",
    "    batch_x1 = torch.tensor(batch_x1, dtype=torch.float32).to(device)\n",
    "    batch_x2 = torch.tensor(batch_x2, dtype=torch.float32).to(device)\n",
    "    batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "    \n",
    "    result_temp = model(batch_x1, batch_x2)\n",
    "    result = np.append(result, result_temp.detach().cpu().numpy())\n",
    "    real_dis = np.append(real_dis, batch_y.detach().cpu())\n",
    "\n",
    "\n",
    "real_dis = real_dis * maxLengthy\n",
    "result = result * maxLengthy\n",
    "\n",
    "abe = np.fabs(real_dis - result)\n",
    "re = abe/real_dis\n",
    "\n",
    "mse = (abe ** 2).mean()\n",
    "maxe = np.max(abe ** 2)\n",
    "mine = np.min(abe ** 2)\n",
    "mabe = abe.mean()\n",
    "maxae = np.max(abe)\n",
    "minae = np.min(abe)\n",
    "mre = re.mean()\n",
    "maxre = np.max(re)\n",
    "minre = np.min(re)\n",
    "print (\"mean square error:\", mse)\n",
    "print (\"max square error:\", maxe)\n",
    "print (\"min square error:\", mine)\n",
    "print (\"mean absolute error:\", mabe)\n",
    "print (\"max absolute error:\", maxae)\n",
    "print (\"min absolute error:\", minae)\n",
    "print (\"mean relative error:\", mre)\n",
    "print (\"max relative error:\", maxre)\n",
    "print (\"min relative error:\", minre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100%|██████████| 629/629 [01:47<00:00,  5.87it/s]\n",
    "# mean square error: 39575.61283054177\n",
    "# max square error: 190603220.47132424\n",
    "# min square error: 0.0\n",
    "# mean absolute error: 143.21570140377924\n",
    "# max absolute error: 13805.912518603189\n",
    "# min absolute error: 0.0\n",
    "# mean relative error: 0.036053427847838056\n",
    "# max relative error: 379.9848707625733\n",
    "# min relative error: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
